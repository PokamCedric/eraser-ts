# Plan d'Optimisation pour algo8

## √âtat Actuel
- **algo8 (Cedric)** : 0.631 ms en moyenne (100 it√©rations sur CRM dataset)
- **73.10x plus rapide** que Floyd-Warshall (algo7)

## Objectif
Optimiser encore plus l'algo8 pour atteindre **120-140x plus rapide** que Floyd-Warshall

---

## üöÄ Propositions d'Optimisation

### 1. **Pr√©-calculer les clusters** (Priorit√©: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)
- **Gain estim√©**: 15-20%
- **Difficult√©**: üü¢ Facile
- **Statut**: ‚¨ú √Ä faire

**Probl√®me actuel** : √Ä chaque step, on parcourt TOUTES les relations pour trouver le cluster
```python
# Ligne 204-207 : O(r) √† chaque step
cluster_elements = []
for left, right in self.relations:
    if right == reference_entity and left not in cluster_elements:
        cluster_elements.append(left)
```

**Solution** : Pr√©-calculer les clusters une seule fois
```python
def __init__(self):
    self.clusters_cache = {}  # {entity: [cluster_elements]}

def _precompute_clusters(self):
    """Pr√©-calcule tous les clusters une seule fois"""
    for entity in self.entities:
        self.clusters_cache[entity] = [left for left, right in self.relations
                                       if right == entity]
```

**Gain** : O(n √ó r) ‚Üí O(r) une seule fois

---

### 2. **Index invers√© pour la propagation** (Priorit√©: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê)
- **Gain estim√©**: 30-40%
- **Difficult√©**: üü° Moyen
- **Statut**: ‚¨ú √Ä faire

**Probl√®me actuel** : La propagation parcourt TOUTES les entit√©s
```python
# Ligne 170-184 : O(n) √† chaque propagation
for entity in self.entity_reference_distances:
    if updated_entity in self.entity_reference_distances[entity]:
        # propagate...
```

**Solution** : Maintenir un index "qui d√©pend de qui"
```python
def __init__(self):
    self.dependents = defaultdict(set)  # {entity: {entities_that_depend_on_it}}

# Au lieu de parcourir tout le monde :
for entity in self.dependents[updated_entity]:
    # Only iterate over actual dependents
```

**Gain** : O(n) ‚Üí O(d) o√π d = nombre de d√©pendances (souvent << n)

---

### 3. **Utiliser des sets au lieu de listes pour cluster_elements** (Priorit√©: ‚≠ê‚≠ê‚≠ê)
- **Gain estim√©**: 5%
- **Difficult√©**: üü¢ Facile
- **Statut**: ‚¨ú √Ä faire

**Probl√®me** : `left not in cluster_elements` est O(n) avec une liste

**Solution** :
```python
cluster_elements = set()
for left, right in self.relations:
    if right == reference_entity:
        cluster_elements.add(left)
```

**Gain** : O(n) ‚Üí O(1) pour les lookups

---

### 4. **√âviter les re-calculs dans `_count_connections`** (Priorit√©: ‚≠ê‚≠ê‚≠ê‚≠ê)
- **Gain estim√©**: 10-15%
- **Difficult√©**: üü¢ Facile
- **Statut**: ‚¨ú √Ä faire

**Probl√®me actuel** : Ligne 263-272, on parcourt toutes les relations pour chaque entit√©
```python
def _count_connections(self):
    for entity in self.entities:
        count = 0
        for left, right in self.relations:  # O(n √ó r)
            if left == entity or right == entity:
                count += 1
```

**Solution** : Calculer une seule fois
```python
def _count_connections_optimized(self):
    connections = defaultdict(int)
    for left, right in self.relations:  # O(r) seulement
        connections[left] += 1
        connections[right] += 1
    return dict(connections)
```

**Gain** : O(n √ó r) ‚Üí O(r)

---

### 5. **Early exit dans la propagation** (Priorit√©: ‚≠ê‚≠ê‚≠ê)
- **Gain estim√©**: 5-10%
- **Difficult√©**: üü¢ Facile
- **Statut**: ‚¨ú √Ä faire

**Probl√®me** : La propagation peut refaire des calculs inutiles

**Solution** : Ajouter un check
```python
def _propagate_distance_update(self, updated_entity, updated_ref, new_dist, visited=None):
    if visited is None:
        visited = set()

    if (updated_entity, updated_ref) in visited:
        return  # Already propagated this path

    visited.add((updated_entity, updated_ref))
    # ... rest of propagation
```

---

### 6. **Batch processing des mises √† jour** (Priorit√©: ‚≠ê‚≠ê)
- **Gain estim√©**: 20-25%
- **Difficult√©**: üî¥ Difficile
- **Statut**: ‚¨ú √Ä faire (Phase 3)

**Probl√®me** : La r√©cursion peut √™tre co√ªteuse

**Solution** : Queue de mises √† jour
```python
def _propagate_distance_update_batch(self, initial_updates):
    queue = deque(initial_updates)

    while queue:
        updated_entity, updated_ref, new_dist = queue.popleft()

        for entity in self.dependents[updated_entity]:
            # Calculate and queue updates
            # √âvite la r√©cursion profonde
```

---

### 7. **Optimisation m√©moire : Sparse storage** (Priorit√©: ‚≠ê)
- **Gain estim√©**: Variable
- **Difficult√©**: üü° Moyen
- **Statut**: ‚¨ú √Ä faire (Optionnel)

**Probl√®me** : `entity_reference_distances` peut devenir grand

**Solution** : Ne stocker que les distances > 1
```python
# Au lieu de stocker toutes les distances de 1
# Ne stocker que celles qui ont √©t√© calcul√©es transitivement
```

---

## üìä Estimation des Gains Cumulatifs

| Optimisation | Gain estim√© | Difficult√© | Priorit√© | Phase |
|--------------|-------------|------------|----------|-------|
| 1. Pr√©-calculer clusters | 15-20% | üü¢ Facile | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Phase 1 |
| 2. Index invers√© propagation | 30-40% | üü° Moyen | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Phase 2 |
| 3. Sets au lieu de listes | 5% | üü¢ Facile | ‚≠ê‚≠ê‚≠ê | Phase 1 |
| 4. Optimiser count_connections | 10-15% | üü¢ Facile | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 1 |
| 5. Early exit propagation | 5-10% | üü¢ Facile | ‚≠ê‚≠ê‚≠ê | Phase 2 |
| 6. Batch processing | 20-25% | üî¥ Difficile | ‚≠ê‚≠ê | Phase 3 |
| 7. Sparse storage | Variable | üü° Moyen | ‚≠ê | Optionnel |

**Gain total estim√© avec optimisations 1-5 : 65-90% suppl√©mentaire**

**Objectif final : ~120-140x plus rapide que Floyd-Warshall !**

---

## üéØ Plan d'Action

### ‚úÖ Phase 1 (Quick wins - 1-2h de dev)
**Gain estim√©: 30-40% suppl√©mentaire**

- [ ] **Optimisation #4** : Optimiser `_count_connections` (10-15% gain)
  - Complexit√©: O(n √ó r) ‚Üí O(r)
  - Impact: Facile et imm√©diat

- [ ] **Optimisation #3** : Utiliser des sets au lieu de listes (5% gain)
  - Complexit√©: O(n) ‚Üí O(1) pour lookups
  - Impact: Tr√®s facile

- [ ] **Optimisation #1** : Pr√©-calculer les clusters (15-20% gain)
  - Complexit√©: O(n √ó r) ‚Üí O(r)
  - Impact: Moyen, structure √† maintenir

**Livrable Phase 1** : algo9.py avec optimisations 1, 3, 4

---

### ‚úÖ Phase 2 (Impact majeur - 3-4h de dev)
**Gain estim√©: 35-50% suppl√©mentaire**

- [ ] **Optimisation #2** : Index invers√© pour propagation (30-40% gain)
  - Complexit√©: O(n) ‚Üí O(d)
  - Impact: Majeur, n√©cessite refactoring de propagation

- [ ] **Optimisation #5** : Early exit dans propagation (5-10% gain)
  - Complexit√©: Ajout de tracking visited
  - Impact: Facile √† ajouter apr√®s #2

**Livrable Phase 2** : algo10.py avec toutes les optimisations 1-5

---

### ‚ö†Ô∏è Phase 3 (Si n√©cessaire - avanc√©)
**Gain estim√©: 20-25% suppl√©mentaire**

- [ ] **Optimisation #6** : Batch processing (20-25% gain)
  - Complexit√©: R√©√©criture de la propagation r√©cursive
  - Impact: Seulement si donn√©es tr√®s denses

- [ ] **Optimisation #7** : Sparse storage (Variable)
  - Complexit√©: Optimisation m√©moire
  - Impact: Pour tr√®s grands graphes

**Livrable Phase 3** : algo11.py (si n√©cessaire)

---

## üìà Benchmarks Pr√©vus

Apr√®s chaque phase, lancer le benchmark:
```bash
python performance_test.py
```

| Version | Temps moyen (ms) | Speedup vs algo7 | Am√©lioration vs algo8 |
|---------|------------------|------------------|----------------------|
| algo7 (Floyd-Warshall) | 46.089 | 1x | - |
| algo8 (Cedric) | 0.631 | 73x | - |
| algo9 (Phase 1) | ~0.40 (estim√©) | ~115x | ~37% |
| algo10 (Phase 2) | ~0.30 (estim√©) | ~154x | ~53% |
| algo11 (Phase 3) | ~0.24 (estim√©) | ~192x | ~62% |

---

## üìù Notes de D√©veloppement

### Checklist Phase 1
1. Cr√©er algo9.py √† partir de algo8.py
2. Impl√©menter optimisation #4 (`_count_connections_optimized`)
3. Impl√©menter optimisation #3 (sets pour clusters)
4. Impl√©menter optimisation #1 (cache des clusters)
5. Tester que les r√©sultats sont identiques
6. Lancer benchmark 100 it√©rations
7. Mettre √† jour la documentation

### Validation
- ‚úÖ Les r√©sultats doivent √™tre **exactement identiques** √† algo8
- ‚úÖ Le temps d'ex√©cution doit √™tre r√©duit de ~30-40%
- ‚úÖ Pas de r√©gression sur les cas limites

---

## üîÑ Historique des Versions

| Version | Date | Description | Performance |
|---------|------|-------------|-------------|
| algo7 | 2025-10-29 | Floyd-Warshall invers√© | 46.089 ms |
| algo8 | 2025-10-29 | Progressive step-by-step | 0.631 ms (73x) |
| algo9 | √Ä venir | Phase 1 optimizations | TBD |
| algo10 | √Ä venir | Phase 2 optimizations | TBD |
| algo11 | √Ä venir | Phase 3 optimizations | TBD |

---

**Derni√®re mise √† jour**: 2025-10-29
**Prochaine √©tape**: Phase 1 - Quick wins
