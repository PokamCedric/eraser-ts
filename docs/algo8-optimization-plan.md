# Plan d'Optimisation pour algo8

## Ã‰tat Actuel
- **algo8 (Cedric)** : 0.631 ms en moyenne (100 itÃ©rations sur CRM dataset)
- **73.10x plus rapide** que Floyd-Warshall (algo7)

## Objectif
Optimiser encore plus l'algo8 pour atteindre **120-140x plus rapide** que Floyd-Warshall

---

## ğŸš€ Propositions d'Optimisation

### 1. **PrÃ©-calculer les clusters** (PrioritÃ©: â­â­â­â­â­)
- **Gain estimÃ©**: 15-20%
- **DifficultÃ©**: ğŸŸ¢ Facile
- **Statut**: â¬œ Ã€ faire

**ProblÃ¨me actuel** : Ã€ chaque step, on parcourt TOUTES les relations pour trouver le cluster
```python
# Ligne 204-207 : O(r) Ã  chaque step
cluster_elements = []
for left, right in self.relations:
    if right == reference_entity and left not in cluster_elements:
        cluster_elements.append(left)
```

**Solution** : PrÃ©-calculer les clusters une seule fois
```python
def __init__(self):
    self.clusters_cache = {}  # {entity: [cluster_elements]}

def _precompute_clusters(self):
    """PrÃ©-calcule tous les clusters une seule fois"""
    for entity in self.entities:
        self.clusters_cache[entity] = [left for left, right in self.relations
                                       if right == entity]
```

**Gain** : O(n Ã— r) â†’ O(r) une seule fois

---

### 2. **Index inversÃ© pour la propagation** (PrioritÃ©: â­â­â­â­â­)
- **Gain estimÃ©**: 30-40%
- **DifficultÃ©**: ğŸŸ¡ Moyen
- **Statut**: â¬œ Ã€ faire

**ProblÃ¨me actuel** : La propagation parcourt TOUTES les entitÃ©s
```python
# Ligne 170-184 : O(n) Ã  chaque propagation
for entity in self.entity_reference_distances:
    if updated_entity in self.entity_reference_distances[entity]:
        # propagate...
```

**Solution** : Maintenir un index "qui dÃ©pend de qui"
```python
def __init__(self):
    self.dependents = defaultdict(set)  # {entity: {entities_that_depend_on_it}}

# Au lieu de parcourir tout le monde :
for entity in self.dependents[updated_entity]:
    # Only iterate over actual dependents
```

**Gain** : O(n) â†’ O(d) oÃ¹ d = nombre de dÃ©pendances (souvent << n)

---

### 3. **Utiliser des sets au lieu de listes pour cluster_elements** (PrioritÃ©: â­â­â­)
- **Gain estimÃ©**: 5%
- **DifficultÃ©**: ğŸŸ¢ Facile
- **Statut**: â¬œ Ã€ faire

**ProblÃ¨me** : `left not in cluster_elements` est O(n) avec une liste

**Solution** :
```python
cluster_elements = set()
for left, right in self.relations:
    if right == reference_entity:
        cluster_elements.add(left)
```

**Gain** : O(n) â†’ O(1) pour les lookups

---

### 4. **Ã‰viter les re-calculs dans `_count_connections`** (PrioritÃ©: â­â­â­â­)
- **Gain estimÃ©**: 10-15%
- **DifficultÃ©**: ğŸŸ¢ Facile
- **Statut**: â¬œ Ã€ faire

**ProblÃ¨me actuel** : Ligne 263-272, on parcourt toutes les relations pour chaque entitÃ©
```python
def _count_connections(self):
    for entity in self.entities:
        count = 0
        for left, right in self.relations:  # O(n Ã— r)
            if left == entity or right == entity:
                count += 1
```

**Solution** : Calculer une seule fois
```python
def _count_connections_optimized(self):
    connections = defaultdict(int)
    for left, right in self.relations:  # O(r) seulement
        connections[left] += 1
        connections[right] += 1
    return dict(connections)
```

**Gain** : O(n Ã— r) â†’ O(r)

---

### 5. **Early exit dans la propagation** (PrioritÃ©: â­â­â­)
- **Gain estimÃ©**: 5-10%
- **DifficultÃ©**: ğŸŸ¢ Facile
- **Statut**: â¬œ Ã€ faire

**ProblÃ¨me** : La propagation peut refaire des calculs inutiles

**Solution** : Ajouter un check
```python
def _propagate_distance_update(self, updated_entity, updated_ref, new_dist, visited=None):
    if visited is None:
        visited = set()

    if (updated_entity, updated_ref) in visited:
        return  # Already propagated this path

    visited.add((updated_entity, updated_ref))
    # ... rest of propagation
```

---

### 6. **Batch processing des mises Ã  jour** (PrioritÃ©: â­â­)
- **Gain estimÃ©**: 20-25%
- **DifficultÃ©**: ğŸ”´ Difficile
- **Statut**: â¬œ Ã€ faire (Phase 3)

**ProblÃ¨me** : La rÃ©cursion peut Ãªtre coÃ»teuse

**Solution** : Queue de mises Ã  jour
```python
def _propagate_distance_update_batch(self, initial_updates):
    queue = deque(initial_updates)

    while queue:
        updated_entity, updated_ref, new_dist = queue.popleft()

        for entity in self.dependents[updated_entity]:
            # Calculate and queue updates
            # Ã‰vite la rÃ©cursion profonde
```

---

### 7. **Optimisation mÃ©moire : Sparse storage** (PrioritÃ©: â­)
- **Gain estimÃ©**: Variable
- **DifficultÃ©**: ğŸŸ¡ Moyen
- **Statut**: â¬œ Ã€ faire (Optionnel)

**ProblÃ¨me** : `entity_reference_distances` peut devenir grand

**Solution** : Ne stocker que les distances > 1
```python
# Au lieu de stocker toutes les distances de 1
# Ne stocker que celles qui ont Ã©tÃ© calculÃ©es transitivement
```

---

## ğŸ“Š Estimation des Gains Cumulatifs

| Optimisation | Gain estimÃ© | DifficultÃ© | PrioritÃ© | Phase |
|--------------|-------------|------------|----------|-------|
| 1. PrÃ©-calculer clusters | 15-20% | ğŸŸ¢ Facile | â­â­â­â­â­ | Phase 1 |
| 2. Index inversÃ© propagation | 30-40% | ğŸŸ¡ Moyen | â­â­â­â­â­ | Phase 2 |
| 3. Sets au lieu de listes | 5% | ğŸŸ¢ Facile | â­â­â­ | Phase 1 |
| 4. Optimiser count_connections | 10-15% | ğŸŸ¢ Facile | â­â­â­â­ | Phase 1 |
| 5. Early exit propagation | 5-10% | ğŸŸ¢ Facile | â­â­â­ | Phase 2 |
| 6. Batch processing | 20-25% | ğŸ”´ Difficile | â­â­ | Phase 3 |
| 7. Sparse storage | Variable | ğŸŸ¡ Moyen | â­ | Optionnel |

**Gain total estimÃ© avec optimisations 1-5 : 65-90% supplÃ©mentaire**

**Objectif final : ~120-140x plus rapide que Floyd-Warshall !**

---

## ğŸ¯ Plan d'Action

### âœ… Phase 1 (Quick wins - 1-2h de dev) - **TERMINÃ‰E**
**Gain rÃ©el: 4.7% (algo9 vs algo8)**

- [x] **Optimisation #4** : Optimiser `_count_connections` (10-15% gain)
  - ComplexitÃ©: O(n Ã— r) â†’ O(r)
  - Impact: Facile et immÃ©diat

- [x] **Optimisation #3** : Utiliser des sets au lieu de listes (5% gain)
  - ComplexitÃ©: O(n) â†’ O(1) pour lookups
  - Impact: TrÃ¨s facile

- [x] **Optimisation #1** : PrÃ©-calculer les clusters (15-20% gain)
  - ComplexitÃ©: O(n Ã— r) â†’ O(r)
  - Impact: Moyen, structure Ã  maintenir

**Livrable Phase 1** : âœ… algo9.py avec optimisations 1, 3, 4

**RÃ©sultats Phase 1:**
- algo8: 0.589 ms
- algo9: 0.562 ms
- **AmÃ©lioration: 4.7%** (1.05x speedup)

**Analyse:** Le gain est modeste car l'algorithme est dÃ©jÃ  trÃ¨s rapide et ces optimisations ciblent des opÃ©rations peu frÃ©quentes.

---

### âœ… Phase 2 (Impact majeur - 3-4h de dev) - **TERMINÃ‰E**
**Gain rÃ©el: 3.9% (algo10 vs algo9), 8.4% total vs algo8**

- [x] **Optimisation #2** : Index inversÃ© pour propagation (30-40% gain)
  - ComplexitÃ©: O(n) â†’ O(d)
  - Impact: Majeur, nÃ©cessite refactoring de propagation

- [x] **Optimisation #5** : Early exit dans propagation (5-10% gain)
  - ComplexitÃ©: Ajout de tracking visited
  - Impact: Facile Ã  ajouter aprÃ¨s #2

**Livrable Phase 2** : âœ… algo10.py avec toutes les optimisations 1-5

**RÃ©sultats Phase 2:**
- algo8: 0.589 ms
- algo9: 0.562 ms
- algo10: 0.540 ms
- **AmÃ©lioration Phase 2: 3.9%** (1.04x speedup vs algo9)
- **AmÃ©lioration totale: 8.4%** (1.09x speedup vs algo8)

**Analyse:** Le gain est Ã©galement modeste car sur le dataset CRM, la propagation ne se dÃ©clenche pas souvent (peu d'intercalations complexes). Les optimisations seraient plus impactantes sur des graphes plus denses avec plus d'intercalations.

---

### âš ï¸ Phase 3 (Si nÃ©cessaire - avancÃ©) - **TERMINÃ‰E** âŒ
**Gain rÃ©el: -2.5% (algo11 vs algo10) - RÃ‰GRESSION**

- [x] **Optimisation #6** : Batch processing (20-25% gain estimÃ©)
  - ComplexitÃ©: RÃ©Ã©criture de la propagation rÃ©cursive
  - Impact: **NÃ‰GATIF sur ce dataset**

- [ ] **Optimisation #7** : Sparse storage (Variable)
  - ComplexitÃ©: Optimisation mÃ©moire
  - Impact: Pour trÃ¨s grands graphes
  - **Statut: Non implÃ©mentÃ©e** (pas nÃ©cessaire)

**Livrable Phase 3** : âœ… algo11.py (implÃ©mentÃ© mais plus lent)

**RÃ©sultats Phase 3:**
- algo8: 0.630 ms
- algo9: 0.568 ms
- algo10: 0.562 ms
- algo11: 0.576 ms (âŒ **plus lent que algo10**)
- **RÃ©gression Phase 3: -2.5%** vs algo10

**Analyse:** Le batch processing introduit un overhead supplÃ©mentaire (gestion de la queue, dÃ©queue operations) qui est plus coÃ»teux que le gain apportÃ© par l'Ã©vitement de la rÃ©cursion. Sur un petit graphe avec peu de propagations profondes, la rÃ©cursion reste plus efficace.

---

## ğŸ“ˆ RÃ©sultats Finaux des Benchmarks

| Version | Temps moyen (ms) | Speedup vs algo7 | AmÃ©lioration vs algo8 | Statut |
|---------|------------------|------------------|----------------------|--------|
| algo7 (Floyd-Warshall) | 46.812 | 1x | - | âœ… Baseline |
| algo8 (Cedric) | 0.630 | **74.3x** | - | âœ… Baseline progressive |
| algo9 (Phase 1) | 0.568 | **82.4x** | **+9.9%** | âœ… RecommandÃ© |
| algo10 (Phase 2) | 0.562 | **83.3x** | **+10.8%** | âœ… **MEILLEUR** |
| algo11 (Phase 3) | 0.576 | 81.2x | +8.6% | âŒ RÃ©gression vs algo10 |

### ğŸ† Recommandation Finale

**Utiliser algo10** comme version de production !

**Raisons:**
- âœ… **Meilleur temps**: 0.562 ms (le plus rapide)
- âœ… **83.3x plus rapide** que Floyd-Warshall
- âœ… **10.8% plus rapide** que algo8
- âœ… Code propre et maintenable
- âœ… Optimisations efficaces (cache, sets, index inversÃ©)

**Ne PAS utiliser algo11:**
- âŒ Plus lent que algo10 (-2.5%)
- âŒ Overhead du batch processing non justifiÃ© sur petits graphes

**Note:** Les rÃ©sultats rÃ©els sont moins spectaculaires que prÃ©vu car:
1. L'algorithme algo8 est dÃ©jÃ  extrÃªmement rapide (< 1ms)
2. Le dataset CRM est relativement petit (41 entitÃ©s, 59 relations)
3. Peu d'intercalations complexes dans ce graphe spÃ©cifique

Les optimisations montreraient des gains plus importants sur:
- Graphes plus grands (>100 entitÃ©s)
- Graphes plus denses (plus de relations par entitÃ©)
- Graphes avec plus d'intercalations transitives

---

## ğŸ“ Notes de DÃ©veloppement

### Checklist Phase 1
1. CrÃ©er algo9.py Ã  partir de algo8.py
2. ImplÃ©menter optimisation #4 (`_count_connections_optimized`)
3. ImplÃ©menter optimisation #3 (sets pour clusters)
4. ImplÃ©menter optimisation #1 (cache des clusters)
5. Tester que les rÃ©sultats sont identiques
6. Lancer benchmark 100 itÃ©rations
7. Mettre Ã  jour la documentation

### Validation
- âœ… Les rÃ©sultats doivent Ãªtre **exactement identiques** Ã  algo8
- âœ… Le temps d'exÃ©cution doit Ãªtre rÃ©duit de ~30-40%
- âœ… Pas de rÃ©gression sur les cas limites

---

## ğŸ”„ Historique des Versions

| Version | Date | Description | Performance |
|---------|------|-------------|-------------|
| algo7 | 2025-10-29 | Floyd-Warshall inversÃ© | 46.089 ms |
| algo8 | 2025-10-29 | Progressive step-by-step | 0.631 ms (73x) |
| algo9 | Ã€ venir | Phase 1 optimizations | TBD |
| algo10 | Ã€ venir | Phase 2 optimizations | TBD |
| algo11 | Ã€ venir | Phase 3 optimizations | TBD |

---

**DerniÃ¨re mise Ã  jour**: 2025-10-29
**Prochaine Ã©tape**: Phase 1 - Quick wins
